{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_cuda = True\n",
    "use_cuda = try_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SameShapeConv1d(torch.nn.Module):\n",
    "    def __init__(self, num_layer, in_channels, out_channels, kernel_size, activation = 'elu', no_act = False):\n",
    "        super(SameShapeConv1d, self).__init__()\n",
    "\n",
    "        self.cnns = torch.nn.ModuleList()\n",
    "        self.num_layer = num_layer\n",
    "        self.no_act = no_act\n",
    "        for idx in range(num_layer):\n",
    "            if idx == 0:\n",
    "                self.cnns.append(torch.nn.Conv1d(in_channels = in_channels, out_channels=out_channels,\n",
    "                                                      kernel_size=kernel_size, stride=1, padding=(kernel_size // 2),\n",
    "                                                      dilation=1, groups=1, bias=True)\n",
    "                )\n",
    "            else:\n",
    "                self.cnns.append(torch.nn.Conv1d(in_channels = out_channels, out_channels=out_channels,\n",
    "                                                      kernel_size=kernel_size, stride=1, padding=(kernel_size // 2),\n",
    "                                                      dilation=1, groups=1, bias=True)\n",
    "                )\n",
    "\n",
    "        if activation == 'elu':\n",
    "            self.activation = F.elu\n",
    "        elif activation == 'relu':\n",
    "            self.activation = F.relu\n",
    "        elif activation == 'selu':\n",
    "            self.activation = F.selu\n",
    "        elif activation == 'prelu':\n",
    "            self.activation = F.prelu\n",
    "        else:\n",
    "            self.activation = F.elu\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = torch.transpose(inputs, 1,2)\n",
    "        x = inputs\n",
    "        for idx in range(self.num_layer):\n",
    "            if self.no_act:\n",
    "                x = self.cnns[idx](x)\n",
    "            else:\n",
    "                x = self.activation(self.cnns[idx](x))\n",
    "\n",
    "        outputs = torch.transpose(x, 1,2)\n",
    "        return outputs\n",
    "\n",
    "class ENCBase(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(ENCBase, self).__init__()\n",
    "\n",
    "        use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "        self.this_device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "        self.args = args\n",
    "        self.reset_precomp()\n",
    "\n",
    "    def set_parallel(self):\n",
    "        pass\n",
    "\n",
    "    def set_precomp(self, mean_scalar, std_scalar):\n",
    "        self.mean_scalar = mean_scalar.to(self.this_device)\n",
    "        self.std_scalar  = std_scalar.to(self.this_device)\n",
    "\n",
    "    # not tested yet\n",
    "    def reset_precomp(self):\n",
    "        self.mean_scalar = torch.zeros(1).type(torch.FloatTensor).to(self.this_device)\n",
    "        self.std_scalar  = torch.ones(1).type(torch.FloatTensor).to(self.this_device)\n",
    "        self.num_test_block= 0.0\n",
    "\n",
    "    def enc_act(self, inputs):\n",
    "        if self.args.enc_act == 'tanh':\n",
    "            return  F.tanh(inputs)\n",
    "        elif self.args.enc_act == 'elu':\n",
    "            return F.elu(inputs)\n",
    "        elif self.args.enc_act == 'relu':\n",
    "            return F.relu(inputs)\n",
    "        elif self.args.enc_act == 'selu':\n",
    "            return F.selu(inputs)\n",
    "        elif self.args.enc_act == 'sigmoid':\n",
    "            return F.sigmoid(inputs)\n",
    "        elif self.args.enc_act == 'linear':\n",
    "            return inputs\n",
    "        else:\n",
    "            return inputs\n",
    "\n",
    "    def power_constraint(self, x_input):\n",
    "\n",
    "        if self.args.no_code_norm:\n",
    "            return x_input\n",
    "        else:\n",
    "            this_mean    = torch.mean(x_input)\n",
    "            this_std     = torch.std(x_input)\n",
    "\n",
    "            if self.args.precompute_norm_stats:\n",
    "                self.num_test_block += 1.0\n",
    "                self.mean_scalar = (self.mean_scalar*(self.num_test_block-1) + this_mean)/self.num_test_block\n",
    "                self.std_scalar  = (self.std_scalar*(self.num_test_block-1) + this_std)/self.num_test_block\n",
    "                x_input_norm = (x_input - self.mean_scalar)/self.std_scalar\n",
    "            else:\n",
    "                x_input_norm = (x_input-this_mean)*1.0 / this_std\n",
    "\n",
    "            if self.args.train_channel_mode == 'block_norm_ste':\n",
    "                stequantize = STEQuantize.apply\n",
    "                x_input_norm = stequantize(x_input_norm, self.args)\n",
    "\n",
    "            if self.args.enc_truncate_limit>0:\n",
    "                x_input_norm = torch.clamp(x_input_norm, -self.args.enc_truncate_limit, self.args.enc_truncate_limit)\n",
    "\n",
    "            return x_input_norm\n",
    "\n",
    "class ENC_interCNN(ENCBase):\n",
    "    def __init__(self, args, p_array):\n",
    "        # turbofy only for code rate 1/3\n",
    "        super(ENC_interCNN, self).__init__(args)\n",
    "        self.args             = args\n",
    "\n",
    "        # Encoder\n",
    "        if self.args.encoder == 'TurboAE_rate3_cnn':\n",
    "            self.enc_cnn_1       = SameShapeConv1d(num_layer=args.enc_num_layer, in_channels=args.code_rate_k,\n",
    "                                                      out_channels= args.enc_num_unit, kernel_size = args.enc_kernel_size)\n",
    "\n",
    "            self.enc_cnn_2       = SameShapeConv1d(num_layer=args.enc_num_layer, in_channels=args.code_rate_k,\n",
    "                                                      out_channels= args.enc_num_unit, kernel_size = args.enc_kernel_size)\n",
    "\n",
    "            self.enc_cnn_3       = SameShapeConv1d(num_layer=args.enc_num_layer, in_channels=args.code_rate_k,\n",
    "                                                      out_channels= args.enc_num_unit, kernel_size = args.enc_kernel_size)\n",
    "        else: # Dense\n",
    "            raise AssertionError(\"SNH\")\n",
    "\n",
    "\n",
    "        self.enc_linear_1    = torch.nn.Linear(args.enc_num_unit, 1)\n",
    "        self.enc_linear_2    = torch.nn.Linear(args.enc_num_unit, 1)\n",
    "        self.enc_linear_3    = torch.nn.Linear(args.enc_num_unit, 1)\n",
    "\n",
    "        self.interleaver      = Interleaver(args, p_array)\n",
    "\n",
    "\n",
    "    def set_interleaver(self, p_array):\n",
    "        self.interleaver.set_parray(p_array)\n",
    "\n",
    "    def set_parallel(self):\n",
    "        self.enc_cnn_1 = torch.nn.DataParallel(self.enc_cnn_1)\n",
    "        self.enc_cnn_2 = torch.nn.DataParallel(self.enc_cnn_2)\n",
    "        self.enc_cnn_3 = torch.nn.DataParallel(self.enc_cnn_3)\n",
    "        self.enc_linear_1 = torch.nn.DataParallel(self.enc_linear_1)\n",
    "        self.enc_linear_2 = torch.nn.DataParallel(self.enc_linear_2)\n",
    "        self.enc_linear_3 = torch.nn.DataParallel(self.enc_linear_3)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        if self.args.is_variable_block_len:\n",
    "            block_len = inputs.shape[1]\n",
    "            # reset interleaver\n",
    "            if self.args.is_interleave != 0:           # fixed interleaver.\n",
    "                seed = np.random.randint(0, self.args.is_interleave)\n",
    "                rand_gen = mtrand.RandomState(seed)\n",
    "                p_array = rand_gen.permutation(arange(block_len))\n",
    "                self.set_interleaver(p_array)\n",
    "\n",
    "        inputs     = 2.0*inputs - 1.0\n",
    "        x_sys      = self.enc_cnn_1(inputs)\n",
    "        x_sys      = self.enc_act(self.enc_linear_1(x_sys))\n",
    "\n",
    "        x_p1       = self.enc_cnn_2(inputs)\n",
    "        x_p1       = self.enc_act(self.enc_linear_2(x_p1))\n",
    "\n",
    "        x_sys_int  = self.interleaver(inputs)\n",
    "        x_p2       = self.enc_cnn_3(x_sys_int)\n",
    "        x_p2       = self.enc_act(self.enc_linear_3(x_p2))\n",
    "\n",
    "        x_tx       = torch.cat([x_sys,x_p1, x_p2], dim = 2)\n",
    "\n",
    "        codes = self.power_constraint(x_tx)\n",
    "\n",
    "        return codes\n",
    "\n",
    "class DEC_LargeCNN(torch.nn.Module):\n",
    "    def __init__(self, args, p_array):\n",
    "        super(DEC_LargeCNN, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "        self.this_device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "        self.interleaver          = Interleaver(args, p_array)\n",
    "        self.deinterleaver        = DeInterleaver(args, p_array)\n",
    "\n",
    "        self.dec1_cnns      = torch.nn.ModuleList()\n",
    "        self.dec2_cnns      = torch.nn.ModuleList()\n",
    "        self.dec1_outputs   = torch.nn.ModuleList()\n",
    "        self.dec2_outputs   = torch.nn.ModuleList()\n",
    "\n",
    "        if self.args.encoder == 'TurboAE_rate3_cnn':\n",
    "            CNNLayer = SameShapeConv1d\n",
    "        else:\n",
    "            raise AssertionError(\"SNH\")\n",
    "\n",
    "\n",
    "        for idx in range(args.num_iteration):\n",
    "            self.dec1_cnns.append(CNNLayer(num_layer=args.dec_num_layer, in_channels=2 + args.num_iter_ft,\n",
    "                                                  out_channels= args.dec_num_unit, kernel_size = args.dec_kernel_size)\n",
    "            )\n",
    "\n",
    "            self.dec2_cnns.append(CNNLayer(num_layer=args.dec_num_layer, in_channels=2 + args.num_iter_ft,\n",
    "                                                  out_channels= args.dec_num_unit, kernel_size = args.dec_kernel_size)\n",
    "            )\n",
    "            self.dec1_outputs.append(torch.nn.Linear(args.dec_num_unit, args.num_iter_ft))\n",
    "\n",
    "            if idx == args.num_iteration -1:\n",
    "                self.dec2_outputs.append(torch.nn.Linear(args.dec_num_unit, 1))\n",
    "            else:\n",
    "                self.dec2_outputs.append(torch.nn.Linear(args.dec_num_unit, args.num_iter_ft))\n",
    "\n",
    "    def set_parallel(self):\n",
    "        for idx in range(self.args.num_iteration):\n",
    "            self.dec1_cnns[idx] = torch.nn.DataParallel(self.dec1_cnns[idx])\n",
    "            self.dec2_cnns[idx] = torch.nn.DataParallel(self.dec2_cnns[idx])\n",
    "            self.dec1_outputs[idx] = torch.nn.DataParallel(self.dec1_outputs[idx])\n",
    "            self.dec2_outputs[idx] = torch.nn.DataParallel(self.dec2_outputs[idx])\n",
    "\n",
    "\n",
    "    def set_interleaver(self, p_array):\n",
    "        self.interleaver.set_parray(p_array)\n",
    "        self.deinterleaver.set_parray(p_array)\n",
    "\n",
    "    def forward(self, received):\n",
    "\n",
    "        if self.args.is_variable_block_len:\n",
    "            block_len = received.shape[1]\n",
    "            # reset interleaver\n",
    "            if self.args.is_interleave != 0:           # fixed interleaver.\n",
    "                seed = np.random.randint(0, self.args.is_interleave)\n",
    "                rand_gen = mtrand.RandomState(seed)\n",
    "                p_array = rand_gen.permutation(arange(block_len))\n",
    "                self.set_interleaver(p_array)\n",
    "        else:\n",
    "            block_len = self.args.block_len\n",
    "\n",
    "        received = received.type(torch.FloatTensor).to(self.this_device)\n",
    "        # Turbo Decoder\n",
    "        r_sys     = received[:,:,0].view((self.args.batch_size, block_len, 1))\n",
    "        r_sys_int = self.interleaver(r_sys)\n",
    "        r_par1    = received[:,:,1].view((self.args.batch_size, block_len, 1))\n",
    "        r_par2    = received[:,:,2].view((self.args.batch_size, block_len, 1))\n",
    "\n",
    "        #num_iteration,\n",
    "        prior = torch.zeros((self.args.batch_size, block_len, self.args.num_iter_ft)).to(self.this_device)\n",
    "\n",
    "        for idx in range(self.args.num_iteration - 1):\n",
    "            x_this_dec = torch.cat([r_sys, r_par1, prior], dim = 2)\n",
    "\n",
    "            x_dec  = self.dec1_cnns[idx](x_this_dec)\n",
    "            x_plr      = self.dec1_outputs[idx](x_dec)\n",
    "\n",
    "            if self.args.extrinsic:\n",
    "                x_plr = x_plr - prior\n",
    "\n",
    "            x_plr_int  = self.interleaver(x_plr)\n",
    "\n",
    "            x_this_dec = torch.cat([r_sys_int, r_par2, x_plr_int ], dim = 2)\n",
    "\n",
    "            x_dec  = self.dec2_cnns[idx](x_this_dec)\n",
    "\n",
    "            x_plr      = self.dec2_outputs[idx](x_dec)\n",
    "\n",
    "            if self.args.extrinsic:\n",
    "                x_plr = x_plr - x_plr_int\n",
    "\n",
    "            prior      = self.deinterleaver(x_plr)\n",
    "\n",
    "        # last round\n",
    "        x_this_dec = torch.cat([r_sys,r_par1, prior], dim = 2)\n",
    "\n",
    "        x_dec     = self.dec1_cnns[self.args.num_iteration - 1](x_this_dec)\n",
    "        x_plr      = self.dec1_outputs[self.args.num_iteration - 1](x_dec)\n",
    "\n",
    "        if self.args.extrinsic:\n",
    "            x_plr = x_plr - prior\n",
    "\n",
    "        x_plr_int  = self.interleaver(x_plr)\n",
    "\n",
    "        x_this_dec = torch.cat([r_sys_int, r_par2, x_plr_int ], dim = 2)\n",
    "\n",
    "        x_dec     = self.dec2_cnns[self.args.num_iteration - 1](x_this_dec)\n",
    "        x_plr      = self.dec2_outputs[self.args.num_iteration - 1](x_dec)\n",
    "\n",
    "        final      = torch.sigmoid(self.deinterleaver(x_plr))\n",
    "\n",
    "        return final\n",
    "\n",
    "class Interleaver(torch.nn.Module):\n",
    "    def __init__(self, args, p_array):\n",
    "        super(Interleaver, self).__init__()\n",
    "        self.args = args\n",
    "        self.p_array = torch.LongTensor(p_array).view(len(p_array))\n",
    "\n",
    "    def set_parray(self, p_array):\n",
    "        self.p_array = torch.LongTensor(p_array).view(len(p_array))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        inputs = inputs.permute(1,0,2)\n",
    "        res    = inputs[self.p_array]\n",
    "        res    = res.permute(1, 0, 2)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class DeInterleaver(torch.nn.Module):\n",
    "    def __init__(self, args, p_array):\n",
    "        super(DeInterleaver, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.reverse_p_array = [0 for _ in range(len(p_array))]\n",
    "        for idx in range(len(p_array)):\n",
    "            self.reverse_p_array[p_array[idx]] = idx\n",
    "\n",
    "        self.reverse_p_array = torch.LongTensor(self.reverse_p_array).view(len(p_array))\n",
    "\n",
    "    def set_parray(self, p_array):\n",
    "\n",
    "        self.reverse_p_array = [0 for _ in range(len(p_array))]\n",
    "        for idx in range(len(p_array)):\n",
    "            self.reverse_p_array[p_array[idx]] = idx\n",
    "\n",
    "        self.reverse_p_array = torch.LongTensor(self.reverse_p_array).view(len(p_array))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.permute(1,0,2)\n",
    "        res    = inputs[self.reverse_p_array]\n",
    "        res    = res.permute(1, 0, 2)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "block_len = 100\n",
    "\n",
    "seed = np.random.randint(0, 1)\n",
    "rand_gen = np.random.mtrand.RandomState(seed)\n",
    "p_array1 = rand_gen.permutation(np.arange(block_len))\n",
    "\n",
    "print('using random interleaver', p_array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size=100, bce_lambda=1.0, bec_p=0.0, bec_p_dec=0.0, ber_lambda=1.0, block_len=100, block_len_high=200,\n",
    "block_len_low=10, bsc_p=0.0, bsc_p_dec=0.0, channel='awgn', code_rate_k=1, code_rate_n=3, dec_act='linear',\n",
    "dec_kernel_size=5, dec_lr=0.001, dec_num_layer=5, dec_num_unit=100, dec_rnn='gru', decoder='TurboAE_rate3_cnn2d',\n",
    "demod_lr=0.005, demod_num_layer=1, demod_num_unit=20, dropout=0.0, enc_act='elu', enc_clipping='both', enc_grad_limit=0.01,\n",
    "enc_kernel_size=5, enc_lr=0.001, enc_num_layer=2, enc_num_unit=100, enc_quantize_level=2, enc_rnn='gru', enc_truncate_limit=0,\n",
    "enc_value_limit=1.0, encoder='TurboAE_rate3_cnn2d', extrinsic=1, focal_alpha=1.0, focal_gamma=0.0, img_size=10,\n",
    "init_nw_weight='default', is_interleave=1, is_k_same_code=False, is_parallel=0, is_same_interleaver=1,\n",
    "is_variable_block_len=False, joint_train=0, k_same_code=2, lambda_maxBCE=0.01, loss='bce', mod_lr=0.005,\n",
    "mod_num_layer=1, mod_num_unit=20, mod_pc='block_power', mod_rate=2, momentum=0.9, no_code_norm=False,\n",
    "no_cuda=False, num_ber_puncture=5, num_block=1000, num_epoch=1, num_iter_ft=5, num_iteration=6, num_train_dec=5,\n",
    "num_train_demod=5, num_train_enc=1, num_train_mod=1, optimizer='adam', precompute_norm_stats=False,\n",
    "print_pos_ber=False, print_pos_power=False, print_test_traj=False, radar_power=5.0, radar_prob=0.05, \n",
    "rec_quantize=False, rec_quantize_level=2, rec_quantize_limit=1.0, snr_points=12, snr_test_end=4.0,\n",
    "snr_test_start=-1.5, test_channel_mode='block_norm', test_ratio=1, train_channel_mode='block_norm',\n",
    "train_dec_channel_high=2.0, train_dec_channel_low=-1.5, train_enc_channel_high=1.0, train_enc_channel_low=1.0, vv=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pickelArgs', 'rb') as handle:\n",
    "    args = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.code_rate_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoder = ENC_interCNN(args, p_array1)\n",
    "decoder = DEC_LargeCNN(args, p_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interleaverTester = torch.arange(0, args.batch_size * args.block_len * args.code_rate_k).view(args.batch_size, args.block_len, args.code_rate_k)\n",
    "interleaverTester.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interleaver(args, p_array1)\n",
    "interleaved = inter(interleaverTester)\n",
    "# interleaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deinter = DeInterleaver(args, p_array1)\n",
    "deinter(interleaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model, check encoder, decoder..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
